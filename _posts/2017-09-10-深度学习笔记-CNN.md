---
layout: post
title: 深度学习笔记-CNN
date: 2020-06-24 12:25:06 -0700
tags: 学习笔记
<!-- comments: true -->
categories: machine learning
---

目前深度学习或者说神经网络按照网络结构的差别主要分为三大类，常规前馈神经网络（Feedforward Neural Network, FNN），卷积神经网络（Convolutional Neural Networks, CNN）和循环神经网络（Recurrent Neural Networks, RNN）。

常规前馈神经网络有很多不同的名称，意思上基本差别不大，这些名称包括：全连接神经网络，多层感知机（Multilayer Perceptron, MLP），人工神经网络（Artificial Neural Network, ANN）等。FNN具有全连接的网络结构，全连接指的是：上一层的神经元与下一层的所有神经元都有连接。“前馈”是相对于“循环”结构而言的，指的是每个神经元只与前一层的神经元相连，接收前一层的输出，并输出给下一层，各层间没有反馈，而在循环结构中，下一层输出会通过某种方式传递给上一层。

CNN也是前馈神经网络的一种。其在人工智能的很多领域都有广泛应用，包括计算机视觉（Computer Vision），语音交互（Voice User Interfaces），自然语言处理（Natural Language Processing）等。

普通神经网络的输入一般是一个向量，而CNN的输入是一个2d的矩阵。在图像识别问题中，图像中的像素点之间是有位置关联信息的，如果使用普通神经网络模型，就需要在输入端把2d图像信息展平成1d向量，这样就丢失了位置信息。而CNN可以直接把图像中像素位置信息以矩阵的形式保留。另外，普通神经网络是全连接网络，这意味着随着节点（神经元）增多，参数数量会很大，而CNN中节点的连接是稀疏的（sparse），每个节点只关注（图像中）某一局部信息，只与上层的部分节点相连（见下图）。

![fig1]({{ site.baseurl}}/images/深度学习笔记-CNN1.jpg)

图1：卷积层中节点只关注局部信息。

了解了CNN的特点，接下来就进入了最核心的部分了，之所以把这种结构称之为卷积神经网络，是因为模型会对输入信息进行卷积运算。首先，我们可以思考一下我们人眼进行图像识别的过程，一个图像可能包含很多因素比如线条的，颜色的等等，其中起主要作用的肯定是物体的线条轮廓（边缘，edges），因此在图像识别的卷积网络中引入线条识别的过滤器（filters）。过滤器就是一个小方块矩阵，比如2×2，3×3的矩阵，被成为卷积核（kernels）。

下图所示为一幅图片与边缘检测卷积核进行卷积运算后得到的图像。

![fig2]({{ site.baseurl}}/images/深度学习笔记-CNN2.jpg)

图2：经边缘检测过滤器过滤后的图像

这种卷积运算具体是一个怎样的过程呢？首先对于黑白图片来说，图片中每个像素点可以用一个数字来表示，这个数字的大小表示的就是这个点的明暗度。因此一个黑白图片可以直接用一个2d矩阵表示出来，比如一个28×28像素的图片可以表示为一个28×28的矩阵。我们现在有一个3×3的卷积核，将其与28×28的矩阵进行卷积运算的过程为：将3×3的卷积核从28×28矩阵的起始点开始平移，每平移一步，与所覆盖区域进行对应乘积和求和运算。说起来太抽象了，很显然这里需要一个动图。

![fig3]({{ site.baseurl}}/images/深度学习笔记-CNN3.gif)

图3：卷积运算过程

上图比较直观的展示了输入矩阵与卷积核进行卷积运算的过程，我们发现经过卷积运算后，图像尺寸由7×7变成了3×3，这是因为上图例子中的步长（stride）为2，也就是每次运算之后卷积核平移两个格，并且没有加padding，padding是什么意思？就是相当于一个矩阵元素全为0的衬底。通过观察上图，可以发现卷积核的中心元素没有机会与输入矩阵四个边上的元素进行乘积运算，这样的后果就是忽略了边缘区域的信息，在kernel为3×3的情况下，如果我们在输入矩阵边缘加一圈1格衬底，然后将步长设为1（padding=1, stride=1），就能够使输入和输出的大小保持一致（如下图）。

![fig4]({{ site.baseurl}}/images/深度学习笔记-CNN4.gif)

图4：padding=1, stride=1, kernel size: 3×3的卷积运算。

现在我们知道了输入矩阵与kernel的运算过程是怎样的，那么kernel这个矩阵怎么设定呢？kernel有不同的设定方法，取决于我们要保留什么样的信息，比如图3中的kernel是中间点为5，十字线上为-1的矩阵，这个kernel是一种高通过滤器（high-pass filters），能够检测颜色迅速变化的区域，起到边缘检测的作用，另外还有一些有趣的kernel比如检测增强横线、竖线等（如下图所示）。这里有个不错的网页：[rnn kernel测试](https://setosa.io/ev/image-kernels/)，可以实验各种常用的kernel，也可以自定义。

![fig5]({{ site.baseurl}}/images/深度学习笔记-CNN5.jpg)

图5：竖线检测增强（左），横线检测增强（右）

现在我们知道了我们可以通过采用不同的卷积核来从输入图片中提取所需要的特征了，上面的例子都是只限于黑白图片，一个图片就是一个2d矩阵，对于RGB图片，每个像素点都是由红、绿、蓝三元素的强度叠加而成，想要处理这种彩色图片，只需要用三个kernel分别作用于这三个颜色通道就可以，相当于将图片的厚度维度由1维变为3维。另外我们还可以增加卷积层的层数，不同层采用不同的kernel来提取图像中的不同特征。在多层卷积网络中，由于每一层的输入信息来自于上一层，因此，在后面的卷积层通常会在上层的基础上提取出更高级别的特征，比如在人脸识别中，最开始的几层卷积层识别横线竖线，曲线等等，后面的卷积层能够识别出眼睛，鼻子等人体器官特征。通过卷积运算识别出图片中的这些特征之后，就可以通过一层或几层普通的全连接神经网络层，甚至其他的机器学习模型来实现图片分类等下游任务。从这里我们可以看出深度神经网络的部分主要是用来做自动特征提取，省去了机器学习过程中手动特征抽取的工作。

使用卷积层能够做到特征提取的作用，但是当我们的节点数量增加，层数增加的时候，又会遇到参数量过大影响运算速度的问题。通常情况下，在一些任务中，比如图像识别分类任务中，如果将一个图片的分辨率调低，也就是将图像缩小，或变模糊，常常不影响我们对物体的辨认。因此，通常在CNN模型中，在每层卷积层后面会加入一层池化层，起到的作用相当于将图像像素调低，或者将图片缩小，从而使层中节点变少，参数也就随之减少。池化的方法有最大池化（max pooling），平均池化（average pooling）等等。过程如下图所示。

![fig6]({{ site.baseurl}}/images/深度学习笔记-CNN6.jpg)

图6：步长为2，filter为2×2的最大池化层将4×4的矩阵缩小为2×2的矩阵。

