---
layout: post
title: 深度学习模型-seq2seq
date: 2020-12-12 12:25:06 -0700
tags: 学习笔记
<!-- comments: true -->
categories: machine learning
---

上一篇文章介绍了RNN模型，模型的结构如下图所示，

![fig1]({{ site.baseurl}}/images/深度学习模型-seq2seq1.png)

图1 RNN模型结构示意图（左：折叠图；右：展开图）

从图中我们可以直观的看出，我们每输入一个序列（比如一句话），都可以得到一个等长的序列，如图中所示，输入为x_1, x_2... x_t-1, x_t，输出为o_1, o_2... o_t-1, o_t。这种模型叫做sequence to sequence的（或者seq2seq），就是输入为序列，输出为序列的模型。

在很多应用中都需要使用这类模型，比如机器翻译，输入一个英文句子，得到一个中文句子。然而有个问题，就是简单基于RNN的seq2seq模型的输入和输出是同样长度的序列。而实际应用中（比如机器翻译）输入和输出的句子不一定是等长的。为了解决这个问题，就设计了一个autoencoder （自编码器）模型，模型的构造如下图（图2）所示，

![fig2]({{ site.baseurl}}/images/深度学习模型-seq2seq2.jpg)

图2 autoencoder模型结构示意图（图中所示的例子为输入一个图片，输出一个图片）

分为两部分：encoder部分和decoder部分，图中所示的例子为输入一个图片（内容为数字2），首先将这个图片输入到encoder部分，然后通过encoder模型生成一个压缩的特征编码：一个向量（图2中的compressed representation）。然后将这个向量输入到decoder部分进行解码，输出结果。在图中所示的例子中，输入图片为数字2，输出图片可以看到还是数字2，但是比输入数据更模糊一些，这是因为encoder在特征压缩的过程中有一些特征被丢失了，导致输出图片分辨率降低。然而正是因为有中间的这个输出的限制，才使得decoder部分可以进行真正的重构，否则我们的输入和输出永远都一样，这个模型也没有什么意义了。

encoder和decoder内部使用什么模型实际上是可以自行构造的，可以是rnn based，也可以是cnn based等。在早先的机器翻译中，encoder和decoder通常都使用多层的rnn 系模型（即rnn, LSTM等）叠加的结构。对于一个句子，我们依次输入这个句子的每个部分（通常是一个单词一个单词的输入）到rnn中，然后rnn会更新其隐藏状态s，整个encoder部分的输出（图2中compressed representation 向量）就是这个句子的最后一个单词输入完成之后的隐藏状态向量s。

decoder和encoder的构造稍微有些区别，decoder中的每一步的输入数据为上一步的输出结果和隐藏状态。如下图3所示，是一个问答的例子，输入数据为：how are you? 最终的输出结果是：I am good。图中的embedding层是将单词数字化的模块（单词转化为向量），word embedding叫做词嵌入，计算机当然不可能直接处理单词，或者汉字等文字，而只能将他们数字化之后才能进行计算，embedding就起了这个作用，把词（或字）转化为数字可以有很多不同的方式，如何使转化后的数字（向量）中包含更多的词的语义信息（某种程度上说是词和词之间的关联的信息）是自然语言处理领域研究的方向之一（这里我把词嵌入这个概念做广义的理解，与词表达（word representation）同义）。

![fig3]({{ site.baseurl}}/images/深度学习模型-seq2seq3.gif)

图3 处理问答问题的autoencoder模型的示意图

这种用rnn最后的隐藏状态作为encoder的输出的设计会导致一个问题，就是输出结果是biased的，会包含更多后半句的信息，而不是前半句的信息。为解决这个问题，就引入了attention的概念，attention的设计就是把encoder和decoder中间的单个向量变成一个更复杂的结构。简单的说是保留rnn的每一步的隐藏状态（每输入一个单词，会产生一个隐藏状态），而不只是最后一个隐藏状态，并且对每个状态分配动态的权重（或者说打分）。分配权重的意义是什么呢？我们可以想象一个人在做翻译，或者回答一个问题的时候，我们在思考答案的时候，每说出一个单词，关注的是输入句子的不同部分，这就是attention也就是 注意力机制的含义。比如在图3所示的例子中，问题是：how are you ？你先看一下，问题里问的是you怎么怎么样，所以我要回答 I 怎么怎么样；然后再看问的是什么，问的是how，然后再结合are you, 你就知道我要回答 I am good. I am bad等。

对每个状态分配动态权重目前有几种不同的方式，比如最简单的就是计算向量的点乘积（但是这种方法过于简单，使得实际的得分取决于词和词之间的相似度（向量的点积与相似度是等同的）），或者更复杂一些可以使用一个微型的神经网络结构，将得分作为这个微模型的输出结果来预测。

用rnn来解决序列问题还有个缺点，就是数据必须依次输入，不能实现并行计算，这样计算速度就会变慢。为解决这个问题，就设计了不含rnn的attention模型：Transformer。transformer在英文里是变压器的意思，这名字也是起的很形象了。Transformer模型的结构如下图所示，图中Feed Forward就是普通的前向神经网络。模型中的encoder和decoder部分都含有attention层，encoder部分含一个self-attention层，decoder部分包含一个encoder-decoder attention和一个self-attention层。

![fig4]({{ site.baseurl}}/images/深度学习模型-seq2seq4.gif)

图4 The Transformer模型结构简化示意图

其中self-attention层是一个序列中的每个部分与该序列中其他部分的联系，下图（图5）中的例子很形象的展示了这一点，图中红色的单词是输入给模型的单词，蓝色标记的部分是每一步pay attention的单词，颜色的深浅表示关注的强弱（权重或者打分的高低）。

![fig5]({{ site.baseurl}}/images/深度学习模型-seq2seq5.jpg)

图5 self-attention举例

encoder-decoder attention我们顾名思义，可以了解到是一个既考虑encoder的输出又考虑decoder的已输出部分的attention模型，而decoder中的另一个self-attention则只关注decoder自身已输出的部分，不关注encoder部分（比如在机器翻译等情况下，保证decoder输出结果是一个符合语法及语言习惯的可以理解的句子）。

Transformer模型中对attention的评分机制的设计是使用三个矩阵（可变参数），分别代表query, key 和value。然后分别与每一步输入数据进行运算（无非乘积，求和，归一化等等，暂不深究）得到最终的评分。

最后提一下sequence to sequence在实际情况下有很多应用场景，除了自然语言处理领域的机器翻译、问答系统，还可以应用于图片与自然语言处理相结合的问题，比如自动为图片生成文字描述

欢迎关注我的公众号获取更多内容

![fig]({{ site.baseurl}}/images/wechat_from0_data.jpg)